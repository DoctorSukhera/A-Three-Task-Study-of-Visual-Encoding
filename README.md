This assignment investigates the principles of visual information processing through the lens of convolutional neural networks (CNNs) using the MNIST handwritten digit dataset. The task comprises three interconnected tasks that explore how visual preprocessing affects information encoding, how hierarchical feature learning occurs in neural networks, and how these systems maintain robustness under various image perturbations. First, I examined three different visual preprocessing methods original pixel values, Difference of Gaussian (DoG) filtering, and Gaussian blurring to understand their impact on feature extraction and classification accuracy. Second, I visualized and analyzed convolutional kernels at different network depths to understand the progression from low-level edge detection to high-level feature combination. Third, I tested model robustness under three perturbation conditions; rotation, occlusion, and noise and analyzed feature space stability using t-SNE visualization. The results demonstrate that while different preprocessing methods yield similar classification performance, they lead to distinct feature representations. The study reveals that occlusion causes the most significant disruption to feature stability, while Gaussian noise is well-tolerated, mirroring patterns observed in biological visual systems.<img width="468" height="179" alt="image" src="https://github.com/user-attachments/assets/696c92eb-031d-4739-a40d-7341a8a91a51" />
